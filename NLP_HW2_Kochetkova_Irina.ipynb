{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Домашнее задание 2 (до 11.10.2022)"
      ],
      "metadata": {
        "id": "JY7f2_bWt1jW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В этой домашке вам будет нужно найти тексты на русском языке (размер корпуса не менее 200 слов), в которых будут какие-то трудные или неоднозначные для POS теггинга моменты и разметить их вручную – с помощью этих текстов мы будем оценивать качество работы наших теггеров. В текстах размечаем только части речи, ничего больше!"
      ],
      "metadata": {
        "id": "yANESbWbu9hE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   (1 балл) Создание, разметка корпуса и объяснение того, почему этот текст подходит для оценки (какие моменты вы тут считаете трудными для автоматического посттеггинга и почему, в этом вам может помочь второй ридинг). Не забывайте, что разные теггеры могут использовать разные тегсеты: напишите комментарий о том, какой тегсет вы берёте для разметки и почему.\n"
      ],
      "metadata": {
        "id": "XltHE3tKuYnj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## План действий\n",
        "*   Создать текстовый файл, куда накидать подходящих нам предложений.\n",
        "*   Создать из него csv из двух столбцов: токен и значение, все значения заполнить pos.\n",
        "*   В ручную поменять pos на часть речи во втором столбце таблицы\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lh9_BNKgf05X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LYqJJ_u6IiQ",
        "outputId": "de258335-dfc4-40bd-88d7-a1fc71b7b93e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0 \n",
        "with open ('Future Standart.txt', encoding='utf8') as in_file:\n",
        "  with open ('Standart.csv', mode=\"w\", encoding='utf-8') as out_file:\n",
        "    file_writer = csv.writer(out_file, delimiter = \",\", lineterminator=\"\\r\")\n",
        "    file_writer.writerow([\"Токен\", \"POS\"])\n",
        "    text = in_file.read()\n",
        "    tocs = [w.lower() for w in word_tokenize(text)]\n",
        "    for word in tocs:\n",
        "      file_writer.writerow([word, \"POS\"]) # Затем в ручную в таблицу подставим тэги\n",
        "      count += 1 # Предложения набирались в ручную, проверим, что кол-во слов подходит под условие \n",
        "print(count)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPTqRG-5h2FG",
        "outputId": "d036fff0-0be7-44f1-e85b-a8c13d1ef67c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Пояснение к корпусу. \n",
        "В корпусе представлены следующие категории слов, трудных для постеггинга:\n",
        "\n",
        "\n",
        "*   Нечастотные слова (встречаются в художественных текстах, вполне нормативны, но малоупотребительны). Например: мусолю (от мусолить), горниле (от горнило), долготерпенье, протодьякон... - эти формы едва ли найдутся во внутреннем словаре программ.\n",
        "*   Частичные омонимы, относящиеся к разным частям речи (про предложению на каждый из вариантов). Например: забрал (забрало/забрать), светило (светить/светило)...\n",
        "*   Слова, пишущиеся через дефис (неделимые): красно белый, нежно-голубой\n",
        "*   Топонимы: Керчь, Волга, Висла (последняя - еще и омоним глаголу)...\n",
        "*   Фамилии, омонимичные разным частям речи: Кулаков, Зайцев.... \n",
        "*   Иностранные Имена: Гомера (от Гомер), Чарльз... \n",
        "*   Уменьшительные имена: Вовка, Максимка...\n",
        "\n"
      ],
      "metadata": {
        "id": "VNCskAwT2imp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Комментарий к тэгсету:\n",
        "Наш набор тэгов будет основываться на универсальном списке:\n",
        "\n",
        "\n",
        "* Прилагательные - Adj (в т.ч. местоимения-прилагательные)\n",
        "* Глаголы -Verb (в т.ч. причастия, деепричастия и ауксильяры)\n",
        "* Существительные (+ местоимения-сущ-ные) - Noun\n",
        "* Наречия -Adj\n",
        "* Междометия - Intj\n",
        "* Предлоги - Prop\n",
        "* Числительные - Num\n",
        "* Частицы - Part\n",
        "* Указательные местоимения - Det\n",
        "* Союз - Conj\n",
        "\n"
      ],
      "metadata": {
        "id": "yhedlPr99Xfq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "2.   (3 балла) Потом вам будет нужно взять три POS теггера для русского языка (udpipe, stanza, natasha, pymorphy, mystem, spacy, deeppavlov) и «прогнать» текст через каждый из них.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EfbSg8hzfbXg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Udpipe"
      ],
      "metadata": {
        "id": "uvQ_ZHWvKJRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ufal.udpipe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRdZ5EjwPEus",
        "outputId": "e2a5fdf1-4fcf-4717-f217-37fae40a44cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ufal.udpipe\n",
            "  Downloading ufal.udpipe-1.2.0.3.tar.gz (304 kB)\n",
            "\u001b[K     |████████████████████████████████| 304 kB 2.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: ufal.udpipe\n",
            "  Building wheel for ufal.udpipe (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ufal.udpipe: filename=ufal.udpipe-1.2.0.3-cp37-cp37m-linux_x86_64.whl size=5626710 sha256=fa71e6617f04bc4b3e6184ff645da42d481527d8ee44fe046704cc91084aecb6\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/b5/8e/3da091629a21ce2d10bf90759d0cb034ba10a5cf7a01e83d64\n",
            "Successfully built ufal.udpipe\n",
            "Installing collected packages: ufal.udpipe\n",
            "Successfully installed ufal.udpipe-1.2.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install corpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0Pn7ck6QFrZ",
        "outputId": "ff7c58b4-d4b9-42a9-e132-1110851c0cf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting corpy\n",
            "  Downloading corpy-0.4.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: ufal.udpipe<2.0,>=1.2 in /usr/local/lib/python3.7/dist-packages (from corpy) (1.2.0.3)\n",
            "Collecting lazy<2.0,>=1.4\n",
            "  Downloading lazy-1.5-py2.py3-none-any.whl (5.0 kB)\n",
            "Requirement already satisfied: click<8.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from corpy) (7.1.2)\n",
            "Requirement already satisfied: wordcloud<2.0.0,>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from corpy) (1.8.2.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from corpy) (2022.6.2)\n",
            "Requirement already satisfied: lxml<5.0.0,>=4.6.1 in /usr/local/lib/python3.7/dist-packages (from corpy) (4.9.1)\n",
            "Collecting ufal.morphodita<2.0,>=1.10\n",
            "  Downloading ufal.morphodita-1.11.0.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (425 kB)\n",
            "\u001b[K     |████████████████████████████████| 425 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16 in /usr/local/lib/python3.7/dist-packages (from corpy) (1.21.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from wordcloud<2.0.0,>=1.8.1->corpy) (3.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from wordcloud<2.0.0,>=1.8.1->corpy) (7.1.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->wordcloud<2.0.0,>=1.8.1->corpy) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->wordcloud<2.0.0,>=1.8.1->corpy) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->wordcloud<2.0.0,>=1.8.1->corpy) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->wordcloud<2.0.0,>=1.8.1->corpy) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->wordcloud<2.0.0,>=1.8.1->corpy) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->wordcloud<2.0.0,>=1.8.1->corpy) (1.15.0)\n",
            "Installing collected packages: ufal.morphodita, lazy, corpy\n",
            "Successfully installed corpy-0.4.0 lazy-1.5 ufal.morphodita-1.11.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install conllu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zf2yl57tiCkZ",
        "outputId": "ae3940c6-1208-4def-b95f-434a9e680c32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting conllu\n",
            "  Downloading conllu-4.5.2-py2.py3-none-any.whl (16 kB)\n",
            "Installing collected packages: conllu\n",
            "Successfully installed conllu-4.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from corpy.udpipe import Model\n",
        "from corpy.udpipe import pprint\n",
        "from conllu import parse\n",
        "m = Model(\"./russian-syntagrus-ud-2.5-191206.udpipe\")\n",
        "\n",
        "horizontal = text\n",
        "conllu_sents = list(m.process(horizontal, in_format=\"horizontal\", out_format=\"conllu\"))\n",
        "data =''\n",
        "for i in conllu_sents:\n",
        "  data += i + '\\n'\n",
        "with open ('Udpipe.csv', mode=\"w\", encoding='utf-8') as out_file:\n",
        "  file_writer = csv.writer(out_file, delimiter = \",\", lineterminator=\"\\r\")\n",
        "  file_writer.writerow([\"Токен\", \"POS\"])\n",
        "  sentences = parse(data)\n",
        "  for sent in sentences:\n",
        "    for token in sent:\n",
        "      file_writer.writerow([token, token['upos']])\n"
      ],
      "metadata": {
        "id": "t_Akw6F7KIZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Natasha"
      ],
      "metadata": {
        "id": "eJJB-dMzo7hd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install natasha"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5u8ACqilgaK",
        "outputId": "e3d6c83f-8ea5-474c-ef48-9fcf5d6d0b61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting natasha\n",
            "  Downloading natasha-1.4.0-py3-none-any.whl (34.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 34.4 MB 166 kB/s \n",
            "\u001b[?25hCollecting razdel>=0.5.0\n",
            "  Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
            "Collecting slovnet>=0.3.0\n",
            "  Downloading slovnet-0.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting yargy>=0.14.0\n",
            "  Downloading yargy-0.15.0-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 130 kB/s \n",
            "\u001b[?25hCollecting ipymarkup>=0.8.0\n",
            "  Downloading ipymarkup-0.9.0-py3-none-any.whl (14 kB)\n",
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 4.0 MB/s \n",
            "\u001b[?25hCollecting navec>=0.9.0\n",
            "  Downloading navec-0.10.0-py3-none-any.whl (23 kB)\n",
            "Collecting intervaltree>=3\n",
            "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from navec>=0.9.0->natasha) (1.21.6)\n",
            "Collecting dawg-python>=0.7.1\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting docopt>=0.6\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 49.6 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: intervaltree, docopt\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26119 sha256=6db3224723a88fa69e3ed1124451787740f9b1c0ea22780d440c7e4bb01d8e7e\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/85/bd/1001cbb46dcfb71c2001cd7401c6fb250392f22a81ce3722f7\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=8f95069b38ade2de03c450c4cb75ea52109cc5324dd9162672a0874f66fe1180\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
            "Successfully built intervaltree docopt\n",
            "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, razdel, pymorphy2, navec, intervaltree, yargy, slovnet, ipymarkup, natasha\n",
            "  Attempting uninstall: intervaltree\n",
            "    Found existing installation: intervaltree 2.1.0\n",
            "    Uninstalling intervaltree-2.1.0:\n",
            "      Successfully uninstalled intervaltree-2.1.0\n",
            "Successfully installed dawg-python-0.7.2 docopt-0.6.2 intervaltree-3.1.0 ipymarkup-0.9.0 natasha-1.4.0 navec-0.10.0 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844 razdel-0.5.0 slovnet-0.5.0 yargy-0.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install slovnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEzILbDZvDbd",
        "outputId": "37b6f528-3014-400c-8ac7-157bfedd4ac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: slovnet in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: navec in /usr/local/lib/python3.7/dist-packages (from slovnet) (0.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from slovnet) (1.21.6)\n",
            "Requirement already satisfied: razdel in /usr/local/lib/python3.7/dist-packages (from slovnet) (0.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from natasha import (\n",
        "    Segmenter,\n",
        "    MorphVocab,\n",
        "    \n",
        "    NewsEmbedding,\n",
        "    NewsMorphTagger,\n",
        "    \n",
        "    PER,\n",
        "    NamesExtractor,\n",
        "\n",
        "    Doc\n",
        ")\n",
        "segmenter = Segmenter()\n",
        "\n",
        "emb = NewsEmbedding()\n",
        "morph_tagger = NewsMorphTagger(emb)\n",
        "\n",
        "doc = Doc(text)\n",
        "doc.segment(segmenter)\n",
        "doc.tag_morph(morph_tagger)\n",
        "tagged = {}\n",
        "with open ('Natasha.csv', mode=\"w\", encoding='utf-8') as out_file:\n",
        "  file_writer = csv.writer(out_file, delimiter = \",\", lineterminator=\"\\r\")\n",
        "  file_writer.writerow([\"Токен\", \"POS\"])\n",
        "  for sent in doc.sents:\n",
        "    x = {_.text: _.pos for _ in sent.tokens}\n",
        "    words = list(x.keys())\n",
        "    pos = list(x.values())\n",
        "    for i in range(len(words)):\n",
        "      file_writer.writerow([words[i], pos[i]])\n",
        "\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "vNLEpYvRrMu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SpaCy"
      ],
      "metadata": {
        "id": "6MRKnJsO3_ye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0p14P7r3-oT",
        "outputId": "e552c84a-e183-463a-8a87-db60f42d6c21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.9.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.1.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.7)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.4)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.8)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.1.2)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.24)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download ru_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TH9_mxHF47mV",
        "outputId": "7d313c14-9fd0-4dde-b2ab-e902d8ba2001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-11 16:34:23.948548: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ru-core-news-sm==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_sm-3.4.0/ru_core_news_sm-3.4.0-py3-none-any.whl (15.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.3 MB 2.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pymorphy2>=0.9 in /usr/local/lib/python3.7/dist-packages (from ru-core-news-sm==3.4.0) (0.9.1)\n",
            "Requirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from ru-core-news-sm==3.4.0) (3.4.1)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2>=0.9->ru-core-news-sm==3.4.0) (0.7.2)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2>=0.9->ru-core-news-sm==3.4.0) (0.6.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2>=0.9->ru-core-news-sm==3.4.0) (2.4.417127.4579844)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (1.9.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (1.0.8)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (0.4.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (0.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (21.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (3.0.7)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (2.4.4)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (8.1.2)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (1.0.3)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (4.1.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (4.64.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (3.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (2.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (5.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (0.7.8)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (0.0.2)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (2.0.1)\n",
            "Installing collected packages: ru-core-news-sm\n",
            "Successfully installed ru-core-news-sm-3.4.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('ru_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"ru_core_news_sm\")\n",
        "doc = nlp(text)\n",
        "with open ('SpaCy.csv', mode=\"w\", encoding='utf-8') as out_file:\n",
        "  file_writer = csv.writer(out_file, delimiter = \",\", lineterminator=\"\\r\")\n",
        "  file_writer.writerow([\"Токен\", \"POS\"])\n",
        "  for i, s in enumerate(doc.sents):\n",
        "    for t in s:\n",
        "      file_writer.writerow([t.text, t.pos])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldO01VJ45hjU",
        "outputId": "0e651aad-e542-4adf-d0cd-9ab97a9baff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Недели\tVERB\n",
            "мусолю\tNOUN\n",
            ".\tPUNCT\n",
            "\n",
            "\tSPACE\n",
            "В\tADP\n",
            "душном\tADJ\n",
            "вагоне\tNOUN\n",
            "–\tPUNCT\n",
            "будто\tSCONJ\n",
            "в\tADP\n",
            "горниле\tNOUN\n",
            ".\tPUNCT\n",
            "\n",
            "\tSPACE\n",
            "Керчь\tPROPN\n",
            "и\tCCONJ\n",
            "Калькутта\tPROPN\n",
            ",\tPUNCT\n",
            "Волга\tPROPN\n",
            "и\tCCONJ\n",
            "Висла\tPROPN\n",
            ".\tPUNCT\n",
            "\n",
            "\tSPACE\n",
            "То\tPRON\n",
            "улетаю\tVERB\n",
            ",\tPUNCT\n",
            "то\tSCONJ\n",
            "отплываю\tVERB\n",
            ".\tPUNCT\n",
            "\n",
            "\tSPACE\n",
            "Слушаю\tVERB\n",
            "притчи\tNOUN\n",
            "о\tADP\n",
            "долготерпенье\tNOUN\n",
            ".\tPUNCT\n",
            "\n",
            "\tSPACE\n",
            "Как\tSCONJ\n",
            "протодьякон\tNOUN\n",
            "в\tADP\n",
            "праздничной\tADJ\n",
            "церкви\tNOUN\n",
            ",\tPUNCT\n",
            "голос\tNOUN\n",
            "единственный\tADJ\n",
            "надрываю\tVERB\n",
            ".\tPUNCT\n",
            "\n",
            "\n",
            "\tSPACE\n",
            "Спросят\tVERB\n",
            "вас\tPRON\n",
            "оробело:“Кто\tPROPN\n",
            "же\tPART\n",
            "тогда\tADV\n",
            "останется\tVERB\n",
            ",\tPUNCT\n",
            "\n",
            "\tSPACE\n",
            "Если\tSCONJ\n",
            "все\tPRON\n",
            "будут\tAUX\n",
            "первыми\tADJ\n",
            ",\tPUNCT\n",
            "Кто\tPRON\n",
            "пойдёт\tVERB\n",
            "в\tADP\n",
            "замыкающих\tVERB\n",
            "?\tPUNCT\n",
            "”\tPUNCT\n",
            "\n",
            "\n",
            "\tSPACE\n",
            "Под\tADP\n",
            "снегом\tNOUN\n",
            "великим\tADJ\n",
            ",\tPUNCT\n",
            "над\tADP\n",
            "временем\tNOUN\n",
            "тысячеверстным\tADJ\n",
            "безмолвные\tADJ\n",
            "крики\tNOUN\n",
            "висят\tVERB\n",
            ",\tPUNCT\n",
            "зацепившись\tVERB\n",
            "за\tADP\n",
            "звезды\tNOUN\n",
            ".\tPUNCT\n",
            "\n",
            "\tSPACE\n",
            "Всего\tADV\n",
            "Гомера\tPROPN\n",
            "знавший\tVERB\n",
            "назубок\tNOUN\n",
            ".\tPUNCT\n",
            "\n",
            "\tSPACE\n",
            "Его\tPRON\n",
            "считал\tVERB\n",
            "своею\tNOUN\n",
            "креатурой\tNOUN\n",
            "тогда\tADV\n",
            "еще\tADV\n",
            "существовавший\tVERB\n",
            "бог\tNOUN\n",
            ".\tPUNCT\n",
            "\n",
            "\tSPACE\n",
            "Мы\tPRON\n",
            "на\tADP\n",
            "роли\tNOUN\n",
            "предателей\tNOUN\n",
            ",\tPUNCT\n",
            "трусов\tNOUN\n",
            ",\tPUNCT\n",
            "иуд\tPROPN\n",
            "в\tADP\n",
            "детских\tADJ\n",
            "играх\tNOUN\n",
            "своих\tDET\n",
            "назначали\tVERB\n",
            "врагов\tNOUN\n",
            ".\tPUNCT\n",
            "\n",
            "\n",
            "\tSPACE\n",
            "Красно\tADJ\n",
            "-\tADJ\n",
            "белый\tADJ\n",
            "\"\tPUNCT\n",
            "Икарус\tNOUN\n",
            "\"\tPUNCT\n",
            ",\tPUNCT\n",
            "ослепительно\tADV\n",
            "чистый\tADJ\n",
            ",\tPUNCT\n",
            "тихий\tADJ\n",
            "и\tCCONJ\n",
            "стремительный\tADJ\n",
            ",\tPUNCT\n",
            "с\tADP\n",
            "надписью\tNOUN\n",
            "\"\tPUNCT\n",
            "Подарок\tNOUN\n",
            "Москвы\tPROPN\n",
            "\"\tPUNCT\n",
            "на\tADP\n",
            "обоих\tNUM\n",
            "бортах\tNOUN\n",
            ".\tPUNCT\n",
            "\n",
            "\tSPACE\n",
            "Борис\tPROPN\n",
            "Зайцев\tPROPN\n",
            ".\tPUNCT\n",
            "\n",
            "\tSPACE\n",
            "Кулаков\tPROPN\n",
            ".\tPUNCT\n",
            "Крепкое\tADJ\n",
            "сообщество\tNOUN\n",
            ".\tPUNCT\n",
            "\n",
            "\tSPACE\n",
            "белые\tADJ\n",
            "перышки\tNOUN\n",
            "облаков\tNOUN\n",
            "аукались\tVERB\n",
            "перышками\tNOUN\n",
            "яхт\tNOUN\n",
            "на\tADP\n",
            "нежно\tADJ\n",
            "-\tADJ\n",
            "голубой\tADJ\n",
            "глади\tNOUN\n",
            ".\tPUNCT\n",
            "\n",
            "\n",
            "\tSPACE\n",
            "Ты\tPRON\n",
            "поймёшь\tNOUN\n",
            ",\tPUNCT\n",
            "что\tPRON\n",
            "узнал\tVERB\n",
            ",\tPUNCT\n",
            "отличил\tVERB\n",
            ",\tPUNCT\n",
            "отыскал\tVERB\n",
            "\n",
            "\tSPACE\n",
            "По\tADP\n",
            "оскалу\tNOUN\n",
            "забрал\tVERB\n",
            "—\tPUNCT\n",
            "это\tPART\n",
            "смерти\tNOUN\n",
            "оскал\tVERB\n",
            "!\tPUNCT\n",
            "\n",
            "\tSPACE\n",
            "И\tCCONJ\n",
            "всегда\tADV\n",
            "позади\tADV\n",
            "вороньё\tADJ\n",
            "и\tCCONJ\n",
            "гробы\tNOUN\n",
            "!\tPUNCT\n",
            "\n",
            "\tSPACE\n",
            "он\tPRON\n",
            "сослепу\tVERB\n",
            "мёл\tNOUN\n",
            "на\tADP\n",
            "него\tPRON\n",
            "мусор\tNOUN\n",
            ".\tPUNCT\n",
            "\n",
            "\tSPACE\n",
            "Но\tCCONJ\n",
            "как\tADV\n",
            "это\tPRON\n",
            "будет\tAUX\n",
            "практически\tADV\n",
            "―\tPUNCT\n",
            "было\tAUX\n",
            "для\tADP\n",
            "меня\tPRON\n",
            "самой\tADJ\n",
            "животрепещущей\tVERB\n",
            "тайной\tNOUN\n",
            ".\tPUNCT\n",
            "\n",
            "\tSPACE\n",
            "В\tADP\n",
            "результате\tNOUN\n",
            "всего\tDET\n",
            "этого\tPRON\n",
            "наше\tDET\n",
            "светило\tNOUN\n",
            ",\tPUNCT\n",
            "сделанное\tVERB\n",
            "из\tADP\n",
            "доброй\tADJ\n",
            "сотни\tNOUN\n",
            "воздушных\tADJ\n",
            "шаров\tNOUN\n",
            ",\tPUNCT\n",
            "появилось\tVERB\n",
            "под\tADP\n",
            "куполом\tNOUN\n",
            "цирка\tNOUN\n",
            ".\tPUNCT\n",
            "\n",
            "\tSPACE\n",
            "Поэтому\tADV\n",
            "в\tADP\n",
            "трилогии\tNOUN\n",
            "Гарева\tPROPN\n",
            "заменил\tVERB\n",
            "Шило\tPROPN\n",
            ".\tPUNCT\n",
            "\n",
            "\tSPACE\n",
            "Год\tNOUN\n",
            "назад\tADV\n",
            "я\tPRON\n",
            "не\tPART\n",
            "пила\tVERB\n",
            ".\tPUNCT\n",
            "\n",
            "\tSPACE\n",
            "Пила\tNOUN\n",
            "и\tCCONJ\n",
            "Анечка\tPROPN\n",
            ".\tPUNCT\n",
            "\n",
            "\tSPACE\n",
            "Пила\tNOUN\n",
            "продолжает\tVERB\n",
            "работать\tVERB\n",
            ",\tPUNCT\n",
            "но\tCCONJ\n",
            "цепь\tNOUN\n",
            "уже\tADV\n",
            "не\tPART\n",
            "движется\tVERB\n",
            ".\tPUNCT\n",
            "\n",
            "\tSPACE\n",
            "жаркое\tADJ\n",
            "из\tADP\n",
            "дикого\tADJ\n",
            "кабана\tNOUN\n",
            ".\tPUNCT\n",
            "\n",
            "\tSPACE\n",
            "В\tADP\n",
            "это\tDET\n",
            "жаркое\tADJ\n",
            ",\tPUNCT\n",
            "сумасшедше\tADJ\n",
            "красивое\tADJ\n",
            "парижское\tADJ\n",
            "лето\tNOUN\n",
            ".\tPUNCT\n",
            "\n",
            "\tSPACE\n",
            "Это\tPRON\n",
            "светило\tVERB\n",
            "над\tADP\n",
            "нами\tPRON\n",
            "солнце\tNOUN\n",
            ".\tPUNCT\n",
            "\n",
            "\tSPACE\n",
            "Зайцев\tPROPN\n",
            "здесь\tADV\n",
            "полно\tADV\n",
            ".\tPUNCT\n",
            "\n",
            "\tSPACE\n",
            "Очевидно\tADV\n",
            ",\tPUNCT\n",
            "брал\tVERB\n",
            "верх\tNOUN\n",
            "инстинкт\tNOUN\n",
            "безоружного\tADJ\n",
            "рода\tNOUN\n",
            "его\tPRON\n",
            ",\tPUNCT\n",
            "не\tPART\n",
            "боявшегося\tVERB\n",
            "силы\tNOUN\n",
            "чужих\tADJ\n",
            "мыслей\tNOUN\n",
            ",\tPUNCT\n",
            "но\tCCONJ\n",
            "боявшегося\tVERB\n",
            "силы\tNOUN\n",
            "чужих\tADJ\n",
            "кулаков\tNOUN\n",
            ".\tPUNCT\n",
            "\n",
            "\tSPACE\n",
            "Потому\tADV\n",
            "что\tSCONJ\n",
            "Вовка\tPROPN\n",
            "у\tADP\n",
            "них\tPRON\n",
            "все\tDET\n",
            "игрушки\tNOUN\n",
            "забрал\tVERB\n",
            ".\tPUNCT\n",
            "\n",
            "\tSPACE\n",
            "Моя\tDET\n",
            "подруга\tNOUN\n",
            "Танька\tPROPN\n",
            ",\tPUNCT\n",
            "детский\tADJ\n",
            "психолог\tNOUN\n",
            ",\tPUNCT\n",
            "считает\tVERB\n",
            ",\tPUNCT\n",
            "что\tSCONJ\n",
            "Максимке\tPROPN\n",
            "совершенно\tADV\n",
            "необходима\tADJ\n",
            "собака\tNOUN\n",
            ".\tPUNCT\n",
            "\n",
            "\tSPACE\n",
            "Чарльз\tPROPN\n",
            "Спенсер\tPROPN\n",
            "Чаплин\tPROPN\n",
            "стал\tVERB\n",
            "звездой\tNOUN\n",
            ",\tPUNCT\n",
            "когда\tSCONJ\n",
            "только\tPART\n",
            "начала\tVERB\n",
            "складываться\tVERB\n",
            "система\tNOUN\n",
            "звёзд\tNOUN\n",
            ".\tPUNCT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "3.   (2 балла) Затем оценим accuracy для каждого теггера. Заметьте, что в разных системах имена тегов и части речи могут отличаться, – вам надо будет свести это всё к единому стандарту с помощью какой-то функции-конвертера и сравнить с вашим размеченным руками эталоном - тоже с помощью какого-то кода или функции.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_FvCQvLXfhrj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Проблемы в сравнении:\n",
        "\n",
        "\n",
        "*   Разные ярлыки частей речи\n",
        "*   Разное кол-во токенов:\n",
        "  * если слово разбилось на два\n",
        "  * если токенизатор не отклеил знак препинания от слова (udpipe)\n",
        "Это мешает корректно сравнивать и находить accuracy\n"
      ],
      "metadata": {
        "id": "tclaMbgj-O-G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Приводим теги к единому набору"
      ],
      "metadata": {
        "id": "Otzyltwm_XTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Theirs_to_mine_dct = {\n",
        "    # udpipe & Natasha\n",
        "    'VERB': 'VERB',\n",
        "'ADP': 'PROP',\n",
        "'ADJ': 'ADJ',\n",
        "'NOUN': '\tNOUN',\n",
        "'PUNCT': 'PUNCT',\n",
        "'PART': 'PART',\n",
        "'CCONJ': 'CONJ',\n",
        "'ADV': 'ADV',\n",
        "'PROPN': 'PROPN',\n",
        "'PRON': 'PRON',\n",
        "'AUX': 'VERB',\n",
        "'SCONJ': 'CONJ',\n",
        "'DET': 'DET',\n",
        "'NUM': 'NUM',\n",
        "    # SpaCy\n",
        "'100': 'VERB',\n",
        "'92': 'NOUN',\n",
        "'97': 'PUNCT',\n",
        "'85': 'PROP',\n",
        "'84': 'ADJ',\n",
        "'98': 'CONJ',\n",
        "'96': 'PROPN',\n",
        "'89': 'CONJ',\n",
        "'95': 'PRON',\n",
        "'94': 'PART',\n",
        "'86': 'ADV',\n",
        "'87': 'VERB',\n",
        "'90': 'DET'}\n",
        "# все три программы используют одинаковый набор тэгов, который отличается от моего тем, что различает типы союзов, и глагол/ауксильяр. \n",
        "# SpyCy странно конвертировал тэги в csv-файле, но проще это исправить здесь (раз уж все равно пишем конвертор)"
      ],
      "metadata": {
        "id": "NuwZizlZ_nj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Считаем Accuracy"
      ],
      "metadata": {
        "id": "qSsWbdzYS_cX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "st_list = []\n",
        "nat_list = []\n",
        "udp_list = []\n",
        "spa_list = []\n",
        "with open('Standart.csv') as st_file:\n",
        "  st = csv.reader(st_file, delimiter=',', quotechar=',')\n",
        "  for row in st:\n",
        "    st_list.append(row[-1])\n",
        "\n",
        "with open('Natasha.csv') as nat_file:\n",
        "  nat = csv.reader(nat_file, delimiter=',', quotechar=',')\n",
        "  for row in nat:\n",
        "    nat_list.append(row[-1])\n",
        "\n",
        "with open('Udpipe.csv') as udp_file:\n",
        "  udp = csv.reader(udp_file, delimiter=',', quotechar=',')\n",
        "  for row in udp:\n",
        "    udp_list.append(row[-1])\n",
        "\n",
        "with open('SpaCy.csv') as spa_file:\n",
        "  spa = csv.reader(spa_file, delimiter=',', quotechar=',')\n",
        "  for row in spa:\n",
        "    spa_list.append(row[-1])"
      ],
      "metadata": {
        "id": "yqa6o3AcTAc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Accuracy (Natasha): %.4f\" % accuracy_score(nat_list, st_list))\n",
        "print(\"Accuracy (Udpipe): %.4f\" % accuracy_score(udp_list, st_list))\n",
        "print(\"Accuracy (SpaCy): %.4f\" % accuracy_score(spa_list, st_list))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPklVKm0l4IX",
        "outputId": "595778a3-0efc-4889-94a9-0adfa31b9bee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (Natasha): 0.6553\n",
            "Accuracy (Udpipe): 0.4286\n",
            "Accuracy (SpaCy): 0.0031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В итоге: Natashа - самый точный (показатели немного занижены из-за того, что кое-где запятые не отделялись от слова, возможно есть связь с тем, что в csv-файлах был поставлен разделитель ','), нет времени проверить, но может быть. если заменить в изначальном csv разделитель на ';', результат еще увеличится"
      ],
      "metadata": {
        "id": "FuUC_b3KnqiF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. (4 балла) Дальше вам нужно взять лучший теггер для русского языка и с его помощью написать функцию (chunker), которая выделяет из размеченного текста 3 типа n-грамм, соответствующих какому-то шаблону (к примеру не + какая-то часть речи или NP или сущ.+ наречие и тд) В предыдущем дз многие из вас справедливо заметили, что если бы мы могли класть в словарь не только отдельные слова, но и словосочетания, то программа работала бы лучше. Предложите 3 шаблона (слово + POS-тег / POS-тег + POS-тег) запись которых в словарь, по вашему мнению, улучшила бы качество работы программы из предыдущей домашки. Балл за объяснение того, почему именно эти группы вы взяли, балл за создание такого рода чанкера, балл за за встраивание функции в программу из предыдущей домашки, балл за сравнение качества предсказания тональности с улучшением и без (это бонусный одиннадцатый балл)."
      ],
      "metadata": {
        "id": "DEaatxphfmtA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Возьмем следующие словосочетания:\n",
        "\n",
        "\n",
        "1.   не + прилагательное (поскольку часто в отзывах бывает что-то типа: \"фильм совсем даже не скучный\", когда 'не', меняет эмоциональное содержание слов на прямо противоположное)\n",
        "2.   не + очень/самый + прилагательное: фильм не очень интересный(эффект примерно такой же как в пункте выше)\n",
        "3.   сущ-ное + прилагательное, так такие словосочетания содержат больше всего описательной информации: плохое качество, красивые костюмы\n",
        "\n"
      ],
      "metadata": {
        "id": "obCUd2tPn0We"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def AN_chunker(text):\n",
        "  collocations = []\n",
        "  segmenter = Segmenter()\n",
        "    doc = Doc(text)\n",
        "    doc.segment(segmenter)\n",
        "    doc.tag_morph(morph_tagger)\n",
        "    for sent in doc.sents:\n",
        "      for i in range(len(sent.tokens)):\n",
        "        if sent.tokens[i].pos == 'ADJ' and i < len(sent.tokens)-1: \n",
        "          if sent.tokens[i + 1].pos == 'NOUN':\n",
        "            collocation = sent.tokens[i] + ' ' + sent.tokens[i + 1]\n",
        "            collocations.append(collocation) \n",
        "  return(collocations)\n",
        "\n",
        "def NegA_chunker(text):\n",
        "  collocations = []\n",
        "  segmenter = Segmenter()\n",
        "  doc = Doc(text)\n",
        "  doc.segment(segmenter)\n",
        "  doc.tag_morph(morph_tagger)\n",
        "  for sent in doc.sents:\n",
        "    for i in range(len(sent.tokens)):\n",
        "        if sent.tokens[i].text == 'не' and i < len(sent.tokens)-1: \n",
        "          if sent.tokens[i + 1].pos == 'ADJ':\n",
        "            collocation = sent.tokens[i] + ' ' + sent.tokens[i + 1]\n",
        "            collocations.append(collocation) \n",
        "  return(collocations)\n",
        "\n",
        "def NegA_chunker_2(text):\n",
        "  collocations = []\n",
        "  segmenter = Segmenter()\n",
        "  doc = Doc(text)\n",
        "  doc.segment(segmenter)\n",
        "  doc.tag_morph(morph_tagger)\n",
        "  for sent in doc.sents:\n",
        "    for i in range(len(sent.tokens)):\n",
        "        if sent.tokens[i].text == 'не' and i < len(sent.tokens)-2: \n",
        "          if sent.tokens[i + 1].text == 'очень' or sent.tokens[i + 1].text == 'самый':\n",
        "            if sent.tokens[i + 2].pos == 'ADJ':\n",
        "              collocation = sent.tokens[i] + ' ' + sent.tokens[i + 1] + ' ' + sent.tokens[i + 2]\n",
        "              collocations.append(collocation) \n",
        "  return(collocations)\n"
      ],
      "metadata": {
        "id": "n91EFYgvuRf5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}